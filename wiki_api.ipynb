{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "\n",
    "To build a model, I will need a large number of plot summaries. I have decided to use\n",
    "Wikipedia as a source for these summaries, since they have lengthy summaries, and they have\n",
    "lists of movies that make it easy to search.\n",
    "\n",
    "To begin with I am testing out individual queries to Wikipedia, to make sure I can pull\n",
    "multiple entries from a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "S = requests.Session()\n",
    "\n",
    "URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "TITLE = \"Category:1961 films|Category:1965 films\"\n",
    "\n",
    "PARAMS = {\n",
    "    'action': \"query\",\n",
    "    'list': 'categorymembers',\n",
    "    'cmtitle': TITLE,\n",
    "    'cmlimit': '10',\n",
    "    'format': \"json\",\n",
    "}\n",
    "\n",
    "R = S.get(url=URL, params=PARAMS)\n",
    "DATA = R.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DATA['error'])\n",
    "#[item['title'] for item in DATA['query']['categorymembers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = []\n",
    "URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "for y in range(1960,1965):\n",
    "    TITLE = \"Category:\" + str(y) + \" films\"\n",
    "\n",
    "    PARAMS = {\n",
    "        'action': \"query\",\n",
    "        'list': 'categorymembers',\n",
    "        'cmtitle': TITLE,\n",
    "        'cmlimit': '10',\n",
    "        'format': \"json\",\n",
    "    }\n",
    "\n",
    "    R = S.get(url=URL, params=PARAMS)\n",
    "    DATA = R.json()\n",
    "    ids = [item['pageid'] for ind,item in enumerate(DATA['query']['categorymembers']) if ind>1]\n",
    "    years.append(ids)\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA['query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA['parse']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is difficult to extract plaintext from the page content that the standard api returns,\n",
    "so I am testing out some wrappers for the api, which may provide extra functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mediawiki import MediaWiki\n",
    "import wikipedia\n",
    "\n",
    "query = \"Category:1961 films\"\n",
    "\n",
    "c = wikipedia.page(pageid=years[3][6])\n",
    "c.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulltext = c.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "ind1 = fulltext.find('== Plot ==') + 10\n",
    "ind2 = fulltext.find('==',ind1)\n",
    "plottext = fulltext[ind1:ind2]\n",
    "plottext.replace('\\n',' ').translate(str.maketrans('','',string.punctuation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `wikipedia` package automatically returns a field called `content` that contains the page as plaintext,\n",
    "so I am going to use that for the specific pages to make extracting the plot easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "from wikiparse_movies import WikiParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have created a WikiParser object with all the functionality I need to make calls to the wikipedia api, and now I am running it to get plots from the years 1960-1965."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "\n",
    "wp = WikiParser()\n",
    "yrs_1960_1970 = wp.get_years(1960,1965)\n",
    "\n",
    "later = datetime.datetime.now()\n",
    "elapsed = later-now\n",
    "print(\"Time: \", elapsed) \n",
    "#year_1960 = movies\n",
    "print(len(yrs_1960_1970))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "yrs1_df = pd.DataFrame.from_dict(yrs_1960_1970)\n",
    "yrs1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yrs1_df = yrs1_df[~yrs1_df['title'].str.startswith('List')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some examination, there are a few problems with this data. The language used to describe foreign films it somehwat unique, and tends to trow off the topic modeling, so it is necessesary to refine the dataset by only using english-language films. Fortunately this is a specific category on wikipedia, so in lieu of search by each year, I only need to search for english-language films. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page: 431 parsing... . . . . . . . . .  \n",
      "page: 432 parsing... . . . . . . . . .  \n",
      "page: 433 parsing... . . . . . . . . .  \n",
      "page: 434 parsing... . . . . . . . . .  \n",
      "page: 435 parsing... . . . . . . . . .  \n",
      "page: 436 parsing... . . . . . . . . .  \n",
      "page: 437 parsing... . . . . . . . . .  \n",
      "page: 438 parsing... . . . . . . . . .  \n",
      "page: 439 parsing... . . . . . . . . .  \n",
      "page: 440 parsing... . . . . . . . . .  \n",
      "page: 441 parsing... . . . . . . . . .  \n",
      "page: 442 parsing... . . . . . . . . .  \n",
      "page: 443 parsing... . . . . . . . . .  \n",
      "page: 444 parsing... . . . . . . . . .  \n",
      "page: 445 parsing... . . . . . . . . .  \n",
      "page: 446 parsing... . . . . . . . . .  \n",
      "page: 447 parsing... . . . . . . . . .  \n",
      "page: 448 parsing... . . . . . . . . .  \n",
      "page: 449 parsing... . . . . . . . . .  \n",
      "page: 450 parsing... . . . . . . . . .  \n",
      "page: 451 parsing... . . . . . . . . .  \n",
      "page: 452 parsing... . . . . . . . . .  \n",
      "page: 453 parsing... . . . . . . . . .  \n",
      "page: 454 parsing... . . . . . . . . .  \n",
      "page: 455 parsing... . . . . . . . . .  \n",
      "page: 456 parsing... . . . . . . . . .  \n",
      "page: 457 parsing... . . . . . . . . .  \n",
      "page: 458 parsing... . . . . . . . . .  \n",
      "page: 459 parsing... . . . . . . . . .  \n",
      "page: 460 parsing... . . . . . . . . .  \n",
      "page: 461 parsing... . . . . . . . . .  \n",
      "page: 462 parsing... . . . . . . . . .  \n",
      "page: 463 parsing... . . . . . . . . .  \n",
      "page: 464 parsing... . . . . . . . . .  \n",
      "page: 465 parsing... . . . . . . . . .  \n",
      "page: 466 parsing... . . . . . . . . .  \n",
      "page: 467 parsing... . . . . . . . . .  \n",
      "page: 468 parsing... . . . . . . . . .  \n",
      "page: 469 parsing... . . . . . . . . .  \n",
      "page: 470 parsing... . . . . . . . . .  \n",
      "page: 471 parsing... . . . . . . . . .  \n",
      "page: 472 parsing... . . . . . . . . .  \n",
      "page: 473 parsing... . . . . . . . . .  \n",
      "page: 474 parsing... . . . . . . . . .  \n",
      "page: 475 parsing... . . . . . . . . .  \n",
      "page: 476 parsing... . . . . . . . . .  \n",
      "page: 477 parsing... . . . . . . . . .  \n",
      "page: 478 parsing... . . . . . . . . .  \n",
      "page: 479 parsing... . . . . . . . .  \n",
      "page: 480 parsing... . . . . . . . . .  \n",
      "page: 481 parsing... . . . . . . . . .  \n",
      "page: 482 parsing... . . . . . . . . .  \n",
      "page: 483 parsing... . . . . . . . . .  \n",
      "page: 484 parsing... . . . . . . . . .  \n",
      "page: 485 parsing... . . . . . . . . .  \n",
      "page: 486 parsing... . . . . . . . . .  \n",
      "page: 487 parsing... . . . . . . . . .  \n",
      "page: 488 parsing... . . . . . . . . .  \n",
      "page: 489 parsing... . . . . . . . . .  \n",
      "page: 490 parsing... . . . . . . . . .  \n",
      "page: 491 parsing... . . . . . . . . .  \n",
      "page: 492 parsing... . . . . . . . . .  \n",
      "page: 493 parsing... . . . . . . . . .  \n",
      "page: 494 parsing... . . . . . . . . .  \n",
      "page: 495 parsing... . . . . . . . . .  \n",
      "page: 496 parsing... . . . . . . . . .  \n",
      "page: 497 parsing... . . . . . . . . .  \n",
      "page: 498 parsing... . . . . . . . . .  \n",
      "page: 499 parsing... . . . . . . . . .  \n",
      "page: 500 parsing... . . . . . . . . .  \n",
      "page: 501 parsing... . . . . . . . . .  \n",
      "page: 502 parsing... . . . . . . . . .  \n",
      "page: 503 parsing... . . . . . . . . .  \n",
      "page: 504 parsing... . . . . . . . . .  \n",
      "page: 505 parsing... . . . . . . . . .  \n",
      "page: 506 parsing... . . . . . . . . .  \n",
      "page: 507 parsing... . . . . . . . . .  \n",
      "page: 508 parsing... . . . . . . . . .  \n",
      "page: 509 parsing... . . . . . . . . .  \n",
      "page: 510 parsing... . . . . . . . . .  \n",
      "page: 511 parsing... . . . . . . . . .  \n",
      "page: 512 parsing... . . . . . . . . .  \n",
      "page: 513 parsing... . . . . . . . . .  \n",
      "page: 514 parsing... . . . . . . . . .  \n",
      "page: 515 parsing... . . . . . . . . .  \n",
      "page: 516 parsing... . . . . . . . . .  \n",
      "page: 517 parsing... . . . . . . . . .  \n",
      "page: 518 parsing... . . . . . . . . .  \n",
      "page: 519 parsing... . . . . . . . . .  \n",
      "page: 520 parsing... . . . . . . . . .  \n",
      "page: 521 parsing... . . . . . . . . .  \n",
      "page: 522 parsing... . . . . . . . . .  \n",
      "page: 523 parsing... . . . . . . . . .  \n",
      "page: 524 parsing... . . . . . . . . .  \n",
      "page: 525 parsing... . . . . . . . . .  \n",
      "page: 526 parsing... . . . . . . . . .  \n",
      "page: 527 parsing... . . . . . . . . .  \n",
      "page: 528 parsing... . . . . . . . . .  \n",
      "page: 529 parsing... . . . . . . . . .  \n",
      "page: 530 parsing... . . . . . . . . .  \n",
      "page: 531 parsing... . . . . . . . . .  \n",
      "page: 532 parsing... . . . . . . . . .  \n",
      "page: 533 parsing... . . . . . . . . .  \n",
      "page: 534 parsing... . . . . . . . . .  \n",
      "page: 535 parsing... . . . . . . . . .  \n",
      "page: 536 parsing... . . . . . . . . .  \n",
      "page: 537 parsing... . . . . . . . . .  \n",
      "page: 538 parsing... . . . . . . . . .  \n",
      "page: 539 parsing... . . . . . . . . .  \n",
      "page: 540 parsing... . . . . . . . . .  \n",
      "page: 541 parsing... . . . . . . . . .  \n",
      "page: 542 parsing... . . . . . . . . .  \n",
      "page: 543 parsing... . . . . . . . . .  \n",
      "page: 544 parsing... . . . . . . . . .  \n",
      "page: 545 parsing... . . . . . . . . .  \n",
      "page: 546 parsing... . . . . . . . . .  \n",
      "page: 547 parsing... . . . . . . . . .  \n",
      "page: 548 parsing... . . . . . . . . .  \n",
      "page: 549 parsing... . . . . . . . . .  \n",
      "page: 550 parsing... . . . . . . . . .  \n",
      "page: 551 parsing... . . . . . . . . .  \n",
      "page: 552 parsing... . . . . . . . . .  \n",
      "page: 553 parsing... . . . . . . . . .  \n",
      "page: 554 parsing... . . . . . . . . .  \n",
      "page: 555 parsing... . . . . . . . . .  \n",
      "page: 556 parsing... . . . . . . . . .  \n",
      "page: 557 parsing... . . . . . . . . .  \n",
      "page: 558 parsing... . . . . . . . . .  \n",
      "page: 559 parsing... . . . . . . . . .  \n",
      "page: 560 parsing... . . . . . . . . .  \n",
      "page: 561 parsing... . . . . . . . . .  \n",
      "page: 562 parsing... . . . . . . . . .  \n",
      "page: 563 parsing... . . . . . . . . .  \n",
      "page: 564 parsing... . . . . . . . . .  \n",
      "page: 565 parsing... . . . . . . . . .  \n",
      "page: 566 parsing... . . . . . . . . .  \n",
      "page: 567 parsing... . . . . . . . . .  \n",
      "page: 568 parsing... . . . . . . . . .  \n",
      "page: 569 parsing... . . . . . . . . .  \n",
      "page: 570 parsing... . . . . . . . . .  \n",
      "page: 571 parsing... . . . . . . . . .  \n",
      "page: 572 parsing... . . . . . . . . .  \n",
      "page: 573 parsing... . . . . . . . . .  \n",
      "page: 574 parsing... . . . . . . . . .  \n",
      "page: 575 parsing... . . . . . . . . .  \n",
      "page: 576 parsing... . . . . . . . . .  \n",
      "page: 577 parsing... . . . . . . . . .  \n",
      "page: 578 parsing... . . . . . . . . .  \n",
      "page: 579 parsing... . . . . . . . . .  \n",
      "page: 580 parsing... . . . . . . . . .  \n",
      "page: 581 parsing... . . . . . . . . .  \n",
      "page: 582 parsing... . . . . . . . . .  \n",
      "page: 583 parsing... . . . . . . . . .  \n",
      "page: 584 parsing... . . . . . . . . .  \n",
      "page: 585 parsing... . . . . . . . . .  \n",
      "page: 586 parsing... . . . . . . . . .  \n",
      "page: 587 parsing... . . . . . . . . .  \n",
      "page: 588 parsing... . . . . . . . . .  \n",
      "page: 589 parsing... . . . . . . . . .  \n",
      "page: 590 parsing... . . . . . . . . .  \n",
      "page: 591 parsing... . . . . . . . . .  \n",
      "page: 592 parsing... . . . . . . . . .  \n",
      "page: 593 parsing... . . . . . . . . .  \n",
      "page: 594 parsing... . . . . . . . . .  \n",
      "page: 595 parsing... . . . . . . . . .  \n",
      "page: 596 parsing... . . . . . . . . .  \n",
      "page: 597 parsing... . . . . . . . . .  \n",
      "page: 598 parsing... . . . . . . . . .  \n",
      "page: 599 parsing... . . . . . . . . .  \n",
      "page: 600 parsing... . . . . . . . . .  \n",
      "page: 601 parsing... . . . . . . . . .  \n",
      "Time:  4:26:49.200782\n",
      "15821\n"
     ]
    }
   ],
   "source": [
    "#430\n",
    "#\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "wp = WikiParser()\n",
    "english_films_2 = wp.get_plots_from_year('English-language',start=431,skip=True)\n",
    "\n",
    "later = datetime.datetime.now()\n",
    "elapsed = later-now\n",
    "print(\"Time: \", elapsed) \n",
    "#year_1960 = movies\n",
    "print(len(english_films_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nn and Raggedy Andy is a tworeel cartoon produ...</td>\n",
       "      <td>Raggedy Ann and Raggedy Andy (1941 film)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nita a divorced mother of two boys works as a...</td>\n",
       "      <td>Raggedy Man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The film centres around the character of Tom ...</td>\n",
       "      <td>The Raggedy Rawney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In 1964 an aging overweight Italian American ...</td>\n",
       "      <td>Raging Bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bruce Pritchard Malcolm McDowell is a 24yearo...</td>\n",
       "      <td>The Raging Moon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             summary  \\\n",
       "0  nn and Raggedy Andy is a tworeel cartoon produ...   \n",
       "1   Nita a divorced mother of two boys works as a...   \n",
       "2   The film centres around the character of Tom ...   \n",
       "3   In 1964 an aging overweight Italian American ...   \n",
       "4   Bruce Pritchard Malcolm McDowell is a 24yearo...   \n",
       "\n",
       "                                      title  \n",
       "0  Raggedy Ann and Raggedy Andy (1941 film)  \n",
       "1                               Raggedy Man  \n",
       "2                        The Raggedy Rawney  \n",
       "3                               Raging Bull  \n",
       "4                           The Raging Moon  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yrs4_df = pd.DataFrame(english_films_2)\n",
    "yrs4_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15821, 2)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yrs4_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have the dataset compiled, I will save it as a json file for temporary storage, until I can get it uploaded to a MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "yrs4_df.to_json('data/eng_431_601.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies1_df = pd.read_json('1960_1964.json')\n",
    "movies2_df = pd.read_json('1965_1970.json')\n",
    "movies_df = movies1_df.append(movies2_df)\n",
    "print(movies_df.shape)\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
